{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests trainning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, mean_absolute_error,mean_squared_error,classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = pd.read_csv(\"training_data_treated.csv\")\n",
    "testDf = pd.read_csv(\"test_data_treated.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trainDf[[\"delay_in_seconds\",\"avg_temperature\",\"avg_atm_pressure\",\"avg_humidity\",\"record_date_month\",\"record_date_day\",\"record_date_isWeekend\",\"record_date_hour\",\"N101\",\"R206\",\"N105\",\"N206\",\"N309\",\"IC5\",\"N310\",\"EM579\",\"N207-4\"]]\n",
    "y = trainDf[[\"incidents\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=13122001,\n",
    "                            n_estimators=1777,\n",
    "                            criterion='entropy',\n",
    "                            max_features='auto',\n",
    "                            class_weight='balanced',\n",
    "                            max_depth= 42,\n",
    "                            min_samples_split=2,\n",
    "                            min_samples_leaf=1,\n",
    "                            n_jobs=-1,\n",
    "                            bootstrap= False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for hyparameter tunning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 1000, stop = 2000, num = 20)]\n",
    "\n",
    "# Criterion of the quality of a split\n",
    "criterion = ['gini','entropy', 'log_loss']\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(20, 150, num = 10)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [1, 2, 4, 6]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1,2,4]\n",
    "\n",
    "n_jobs = [-1]\n",
    "\n",
    "random_state = [13122001]\n",
    "\n",
    "class_weight = ['balanced']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'criterion' : criterion,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'n_jobs' :n_jobs,\n",
    "               'random_state' : random_state,\n",
    "               'class_weight' : class_weight,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation,   \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = GridSearchCV(estimator = clf, param_grid = random_grid, cv = 3, verbose=2)# Fit the random search model\n",
    "\n",
    "#Activate this line to perform hyperparameter search\n",
    "#rf_random.fit(x, y.values.ravel())\n",
    "#print(rf_random.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation and training with 10 KFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9314000000000002\n"
     ]
    }
   ],
   "source": [
    "scores =[]\n",
    "kf = KFold(n_splits=10)\n",
    "for train,test in kf.split(x): \n",
    "    clf.fit(x.loc[train,:],y.loc[train,:].values.ravel())\n",
    "    score = clf.score(x.loc[test,:],y.loc[test,:])\n",
    "    scores.append(score)\n",
    "    y_predicted = clf.predict(x.loc[test,:])\n",
    "    #print(confusion_matrix(y.loc[test,:],y_predicted))\n",
    "    #print(score)   \n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados at√© agora:\n",
    "\n",
    "Features: \"delay_in_seconds\",\"avg_temperature\",\"avg_atm_pressure\",\"avg_humidity\",\"record_date_month\",\"record_date_day\",\"record_date_isWeekend\",\"record_date_hour\",\"N101\",\"R206\",\"N105\",\"N206\",\"N309\",\"IC5\",\"N310\",\"EM579\",\"N207-4\"\n",
    "\n",
    "Clf : RandomForestClassifier(n_estimators = 100,random_state=13122001) \n",
    "\n",
    "Acc: 0.9251999999999999\n",
    "\n",
    "%------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Features : \"delay_in_seconds\",\"avg_temperature\",\"avg_atm_pressure\",\"avg_humidity\",\"avg_wind_speed\",\"avg_rain\",\"record_date_month\",\"record_date_day\",\"record_date_isWeekend\",\"record_date_hour\",\"N101\",\"R206\",\"N105\",\"N206\",\"N309\",\"IC5\",\"N310\",\"EM579\",\"N207-4\"\n",
    "\n",
    "\n",
    "Clf : RandomForestClassifier(n_estimators = 100,random_state=13122001) \n",
    "\n",
    "Acc: 0.9187999999999998\n",
    "\n",
    "%------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Features : \"delay_in_seconds\",\"avg_temperature\",\"avg_atm_pressure\",\"avg_humidity\",\"record_date_month\",\"record_date_isWeekend\",\"record_date_hour\",\"N101\",\"R206\",\"N105\",\"N206\",\"N309\",\"IC5\",\"N310\",\"EM579\",\"N207-4\"\n",
    "\n",
    "Clf : RandomForestClassifier(n_estimators = 100,random_state=13122001) \n",
    "\n",
    "Acc: 0.8848\n",
    "\n",
    "%------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Features: \"delay_in_seconds\",\"avg_temperature\",\"avg_atm_pressure\",\"avg_humidity\",\"record_date_month\",\"record_date_day\",\"record_date_isWeekend\",\"record_date_hour\",\"N101\",\"R206\",\"N105\",\"N206\",\"N309\",\"IC5\",\"N310\",\"EM579\",\"N207-4\"\n",
    "\n",
    "Clf : RandomForestClassifier(n_estimators = 1400,random_state=13122001,min_samples_split= 2,min_samples_leaf= 1,max_depth= 40,bootstrap= False) \n",
    "\n",
    "\n",
    "Acc: 0.9282\n",
    "\n",
    "%------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Features: \"delay_in_seconds\",\"avg_temperature\",\"avg_atm_pressure\",\"avg_humidity\",\"record_date_month\",\"record_date_day\",\"record_date_isWeekend\",\"record_date_hour\",\"N101\",\"R206\",\"N105\",\"N206\",\"N309\",\"IC5\",\"N310\",\"EM579\",\"N207-4\"\n",
    "\n",
    "Clf : RandomForestClassifier(n_estimators = 1400,random_state=13122001,min_samples_split= 2,min_samples_leaf= 1,max_depth= 40,bootstrap= False,criterion=\"entropy\") \n",
    "\n",
    "\n",
    "Acc: 0.9308\n",
    "\n",
    "%------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Features: \"delay_in_seconds\",\"avg_temperature\",\"avg_atm_pressure\",\"avg_humidity\",\"record_date_month\",\"record_date_day\",\"record_date_isWeekend\",\"record_date_hour\",\"N101\",\"R206\",\"N206\",\"N309\",\"IC5\",\"N310\",\"EM579\",\"N207-4\"\n",
    "\n",
    "Clf : RandomForestClassifier(n_estimators = 1400,random_state=13122001,min_samples_split= 2,min_samples_leaf= 1,max_depth= 40,bootstrap= False,criterion=\"entropy\") \n",
    "\n",
    "\n",
    "Acc: 0.9326\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = trainDf[[\"delay_in_seconds\",\"avg_temperature\",\"avg_atm_pressure\",\"avg_humidity\",\"record_date_month\",\"record_date_day\",\"record_date_isWeekend\",\"record_date_hour\",\"N101\",\"R206\",\"N105\",\"N206\",\"N309\",\"IC5\",\"N310\",\"EM579\",\"N207-4\"]]\n",
    "y_train = trainDf[[\"incidents\"]]\n",
    "x_test = testDf[[\"delay_in_seconds\",\"avg_temperature\",\"avg_atm_pressure\",\"avg_humidity\",\"record_date_month\",\"record_date_day\",\"record_date_isWeekend\",\"record_date_hour\",\"N101\",\"R206\",\"N105\",\"N206\",\"N309\",\"IC5\",\"N310\",\"EM579\",\"N207-4\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a RF classifier\n",
    "#clf2 = RandomForestClassifier(n_estimators = 1400,random_state=13122001,min_samples_split= 2,min_samples_leaf= 1,max_depth= 40,bootstrap= False,criterion=\"entropy\")\n",
    "clf = RandomForestClassifier(random_state=13122001,\n",
    "                            n_estimators=1777,\n",
    "                            criterion='entropy',\n",
    "                            max_features='auto',\n",
    "                            class_weight='balanced',\n",
    "                            max_depth= 42,\n",
    "                            min_samples_split=2,\n",
    "                            min_samples_leaf=1,\n",
    "                            n_jobs=-1,\n",
    "                            bootstrap= False) \n",
    "\n",
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "clf.fit(x_train,y_train.values.ravel())\n",
    " \n",
    "# performing predictions on the test dataset\n",
    "y_pred = clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1206\n"
     ]
    }
   ],
   "source": [
    "f = open(\"Submissions/forestSub.csv\", \"w\")\n",
    "\n",
    "replace_map = {0:'None', 1:'Low', 2:'Medium',3:'High',4:'Very_High'}\n",
    "\n",
    "print(y_pred.size)\n",
    "\n",
    "\n",
    "f.write(\"RowId,Incidents\\n\")\n",
    "\n",
    "for i in range(y_pred.size):\n",
    "    f.write(str(i+1))\n",
    "    f.write(\",\")\n",
    "    f.write(replace_map[y_pred[i]])\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many lines changed compared to the best submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "count = 0\n",
    "filename1 = \"Submissions/bestSub.csv\"\n",
    "filename2 = \"Submissions/forestSub.csv\"\n",
    "count2=0\n",
    "\n",
    "with open(filename1) as file1, open(filename2) as file2:\n",
    "    for line_file_1, line_file_2 in zip(file1, file2):\n",
    "        if line_file_1 != line_file_2:\n",
    "            count += 1\n",
    "        else: count2+=1\n",
    "\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb50656a97d90f3364306f1185a9a91686dc76292645ad8896f0c9fab5293942"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
