{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests trainning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score,classification_report,accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = pd.read_csv(\"training_data_treated.csv\")\n",
    "testDf = pd.read_csv(\"test_data_treated.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def featureSelect(trainDf):\n",
    "    #return trainDf[[\"delay_in_seconds\",\"avg_temperature\",\"avg_atm_pressure\",\"record_date_month\",\"record_date_day\",\"record_date_isWeekend\",\"record_date_hour\",\"N101\",\"IC5\",\"Affected_Count\"]]\n",
    "    return trainDf[[\"delay_in_seconds\",\"avg_atm_pressure\",\"record_date_month\",\"record_date_day\",\"dayYear\",\"record_date_isWeekend\",\"record_date_hour\",\"N101\",\"IC5\",\"Affected_Count\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "x  = featureSelect(trainDf)\n",
    "y = trainDf[[\"incidents\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature select testing using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#pca = PCA(n_components=10)\n",
    "#principalComponents = pca.fit_transform(x)\n",
    "#x = pd.DataFrame(data = principalComponents\n",
    "#             , columns = ['principal component 1', 'principal component 2','principal component 3','principal component 4','principal component 5','principal component 6','principal component 7','principal component 8','principal component 9','principal component 10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForestModel():\n",
    "    return RandomForestClassifier(random_state=13032001,\n",
    "                            n_estimators=1777,\n",
    "                            criterion='entropy',\n",
    "                            max_features='auto',\n",
    "                            class_weight='balanced',\n",
    "                            max_depth= 34,\n",
    "                            min_samples_split=2,\n",
    "                            min_samples_leaf=1,\n",
    "                            n_jobs=-1,\n",
    "                            bootstrap= False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for hyparameter tunning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 1000, stop = 2000, num = 20)]\n",
    "\n",
    "# Criterion of the quality of a split\n",
    "criterion = ['gini','entropy', 'log_loss']\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(20, 150, num = 10)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [1, 2, 4, 6]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1,2,4]\n",
    "\n",
    "n_jobs = [-1]\n",
    "\n",
    "random_state = [13122001]\n",
    "\n",
    "class_weight = ['balanced']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'criterion' : criterion,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'n_jobs' :n_jobs,\n",
    "               'random_state' : random_state,\n",
    "               'class_weight' : class_weight,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "clf = randomForestModel()\n",
    "# Random search of parameters, using 3 fold cross validation,   \n",
    "# search across 100 different combinations, and use all available cores\n",
    "#rf_random = GridSearchCV(estimator = clf, param_grid = random_grid, cv = 3, verbose=2)# Fit the random search model\n",
    "\n",
    "#Activate this line to perform hyperparameter search\n",
    "#rf_random.fit(x, y.values.ravel())\n",
    "#print(rf_random.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small test using SMOTE oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       630\n",
      "           1       0.89      0.92      0.91       215\n",
      "           2       0.88      0.87      0.88       166\n",
      "           3       0.90      0.90      0.90       311\n",
      "           4       0.91      0.90      0.91       178\n",
      "\n",
      "    accuracy                           0.94      1500\n",
      "   macro avg       0.92      0.92      0.92      1500\n",
      "weighted avg       0.94      0.94      0.94      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "\n",
    "oversample = SMOTE(sampling_strategy={0:1398,1:762,2:700,3:762,4:762},random_state=13122001)\n",
    "x_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "clf.fit(x_over,y_over.values.ravel())\n",
    "predictions = clf.predict(X_test)\n",
    "  \n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small test using NearMiss undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       630\n",
      "           1       0.90      0.93      0.91       215\n",
      "           2       0.89      0.86      0.87       166\n",
      "           3       0.91      0.91      0.91       311\n",
      "           4       0.92      0.90      0.91       178\n",
      "\n",
      "    accuracy                           0.94      1500\n",
      "   macro avg       0.92      0.92      0.92      1500\n",
      "weighted avg       0.94      0.94      0.94      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# apply near miss\n",
    "from imblearn.under_sampling import NearMiss\n",
    "nr = NearMiss(sampling_strategy={0:1100,1:503,2:412,3:762,4:425})\n",
    "\n",
    "X_train_miss, y_train_miss = nr.fit_resample(X_train, y_train)\n",
    "\n",
    "clf.fit(X_train_miss,y_train_miss.values.ravel())\n",
    "predictions = clf.predict(X_test)\n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation and training with 10 KFolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Acc: 0.946 F1Score: 0.9458757017804462\n",
      "[2] Acc: 0.94 F1Score: 0.9401964089229568\n",
      "[3] Acc: 0.93 F1Score: 0.9298087949095163\n",
      "[4] Acc: 0.94 F1Score: 0.9400846194760961\n",
      "[5] Acc: 0.92 F1Score: 0.919794965899812\n",
      "[6] Acc: 0.932 F1Score: 0.9320466600638274\n",
      "[7] Acc: 0.95 F1Score: 0.9497936656379635\n",
      "[8] Acc: 0.944 F1Score: 0.9440985257301536\n",
      "[9] Acc: 0.934 F1Score: 0.9339468452874173\n",
      "[10] Acc: 0.944 F1Score: 0.9439691511065221\n",
      "Average: 0.938\n"
     ]
    }
   ],
   "source": [
    "scores =[]\n",
    "kf = KFold(n_splits=10,shuffle=True)  # we dont need random seed here if cross validation is desired\n",
    "counter =1\n",
    "\n",
    "for train,test in kf.split(x):\n",
    "    clf.fit(x.loc[train,:],y.loc[train,:].values.ravel())\n",
    "    score = clf.score(x.loc[test,:],y.loc[test,:])\n",
    "    scores.append(score)\n",
    "    y_predicted = clf.predict(x.loc[test,:])\n",
    "    f1 = f1_score(y.loc[test,:],y_predicted,average=\"weighted\")\n",
    "    print(\"[\"+ str(counter) +\"] Acc:\",score,\"F1Score:\", f1)\n",
    "    counter+=1\n",
    "print(\"Average:\",np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = featureSelect(trainDf)\n",
    "y_train = trainDf[[\"incidents\"]]\n",
    "\n",
    "\n",
    "x_test =featureSelect(testDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a RF classifier\n",
    "clf = randomForestModel()\n",
    "\n",
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "clf.fit(x,y.values.ravel())\n",
    " \n",
    "# performing predictions on the test dataset\n",
    "y_pred = clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1206\n"
     ]
    }
   ],
   "source": [
    "f = open(\"Submissions/forestSub.csv\", \"w\")\n",
    "\n",
    "replace_map = {0:'None', 1:'Low', 2:'Medium',3:'High',4:'Very_High'}\n",
    "\n",
    "print(y_pred.size)\n",
    "\n",
    "\n",
    "f.write(\"RowId,Incidents\\n\")\n",
    "\n",
    "for i in range(y_pred.size):\n",
    "    f.write(str(i+1))\n",
    "    f.write(\",\")\n",
    "    f.write(replace_map[y_pred[i]])\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many lines changed compared to the best submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "count = 0\n",
    "filename1 = \"Submissions/bestSub.csv\"\n",
    "filename2 = \"Submissions/forestSub.csv\"\n",
    "count2=0\n",
    "\n",
    "with open(filename1) as file1, open(filename2) as file2:\n",
    "    for line_file_1, line_file_2 in zip(file1, file2):\n",
    "        if line_file_1 != line_file_2:\n",
    "            count += 1\n",
    "        else: count2+=1\n",
    "\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb50656a97d90f3364306f1185a9a91686dc76292645ad8896f0c9fab5293942"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
