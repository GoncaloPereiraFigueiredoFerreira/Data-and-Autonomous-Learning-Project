{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score,classification_report,accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDf = pd.read_csv(\"training_data_treated.csv\")\n",
    "testDf = pd.read_csv(\"test_data_treated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureSelect(trainDf):\n",
    "    return trainDf[[\"delay_in_seconds\",\"avg_temperature\",\"avg_atm_pressure\",\"record_date_month\",\"record_date_day\",\"record_date_isWeekend\",\"record_date_hour\",\"N101\",\"IC5\",\"Affected_Count\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = featureSelect(trainDf)\n",
    "y = trainDf[[\"incidents\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 1000, stop = 2000, num = 20)]\n",
    "\n",
    "# Criterion of the quality of a split\n",
    "criterion = ['gini','entropy', 'log_loss']\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(20, 150, num = 10)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [1, 2, 4, 6]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1,2,4]\n",
    "\n",
    "n_jobs = [-1]\n",
    "\n",
    "random_state = [13122001]\n",
    "\n",
    "class_weight = ['balanced']\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'criterion' : criterion,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'n_jobs' :n_jobs,\n",
    "               'random_state' : random_state,\n",
    "               'class_weight' : class_weight,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "def retXGBoost():\n",
    "    return  xgb.XGBClassifier(\n",
    "              booster='gbtree',\n",
    "              colsample_bynode=0.8, colsample_bytree=1, eval_metric='mlogloss',\n",
    "              gamma=15, importance_type=\"total_cover\",\n",
    "              interaction_constraints='', learning_rate=0.05,\n",
    "              max_delta_step=15, max_depth=6, min_child_weight=1, \n",
    "              n_estimators=1000, n_jobs=16, min_split_loss =0,\n",
    "              objective='multi:softprob', random_state=13122001,\n",
    "              subsample=0.5,\n",
    "              use_label_encoder=False,\n",
    "              validate_parameters=1, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = retXGBoost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Acc: 0.93 F1Score: 0.9299591843956709\n",
      "[2] Acc: 0.934 F1Score: 0.9340761221889844\n",
      "[3] Acc: 0.936 F1Score: 0.9358686949432237\n",
      "[4] Acc: 0.92 F1Score: 0.9203484521355875\n",
      "[5] Acc: 0.94 F1Score: 0.9397538340051673\n",
      "[6] Acc: 0.928 F1Score: 0.9278962647325912\n",
      "[7] Acc: 0.944 F1Score: 0.9439468410076749\n",
      "[8] Acc: 0.926 F1Score: 0.9252406649409811\n",
      "[9] Acc: 0.92 F1Score: 0.9196049189055657\n",
      "[10] Acc: 0.952 F1Score: 0.95231000606895\n",
      "Average: 0.933\n"
     ]
    }
   ],
   "source": [
    "scores =[]\n",
    "kf = KFold(n_splits=10)\n",
    "counter=1\n",
    "for train,test in kf.split(x):\n",
    "    clf.fit(x.loc[train,:],y.loc[train,:].values.ravel())\n",
    "    score = clf.score(x.loc[test,:],y.loc[test,:])\n",
    "    scores.append(score)\n",
    "    y_predicted = clf.predict(x.loc[test,:])\n",
    "    f1 = f1_score(y.loc[test,:],y_predicted,average=\"weighted\")\n",
    "    print(\"[\"+ str(counter) +\"] Acc:\",score,\"F1Score:\", f1)\n",
    "    counter+=1\n",
    "print(\"Average:\",np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = featureSelect(trainDf)\n",
    "y_train = trainDf[[\"incidents\"]]\n",
    "\n",
    "x_test =featureSelect(testDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a RF classifier\n",
    "#clf2 = RandomForestClassifier(n_estimators = 1400,random_state=13122001,min_samples_split= 2,min_samples_leaf= 1,max_depth= 40,bootstrap= False,criterion=\"entropy\")\n",
    "clf = retXGBoost()\n",
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "clf.fit(x_train,y_train.values.ravel())\n",
    " \n",
    "# performing predictions on the test dataset\n",
    "y_pred = clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1206\n"
     ]
    }
   ],
   "source": [
    "f = open(\"Submissions/xgboostSub.csv\", \"w\")\n",
    "\n",
    "replace_map = {0:'None', 1:'Low', 2:'Medium',3:'High',4:'Very_High'}\n",
    "\n",
    "print(y_pred.size)\n",
    "\n",
    "\n",
    "f.write(\"RowId,Incidents\\n\")\n",
    "\n",
    "for i in range(y_pred.size):\n",
    "    f.write(str(i+1))\n",
    "    f.write(\",\")\n",
    "    f.write(replace_map[y_pred[i]])\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "count = 0\n",
    "filename1 = \"Submissions/bestSub.csv\"\n",
    "filename2 = \"Submissions/xgboostSub.csv\"\n",
    "count2=0\n",
    "\n",
    "with open(filename1) as file1, open(filename2) as file2:\n",
    "    for line_file_1, line_file_2 in zip(file1, file2):\n",
    "        if line_file_1 != line_file_2:\n",
    "            count += 1\n",
    "        else: count2+=1\n",
    "\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb50656a97d90f3364306f1185a9a91686dc76292645ad8896f0c9fab5293942"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
